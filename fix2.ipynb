{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_targer' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://coremltools.readme.io/docs/unified-conversion-api#target-conversion-formats\n",
      "Model is not in eval mode. Consider calling '.eval()' on your model prior to conversion\n",
      "Converting PyTorch Frontend ==> MIL Ops:  75%|███████▌  | 3/4 [00:00<00:00, 1985.63 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 9859.67 passes/s]\n",
      "Running MIL default pipeline:   0%|          | 0/71 [00:00<?, ? passes/s]/Users/surajmahapatra/Library/Python/3.9/lib/python/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:267: UserWarning: Output, '6', of the source model, has been renamed to 'var_6' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|██████████| 71/71 [00:00<00:00, 4265.31 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 25758.26 passes/s]\n",
      "When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_targer' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://coremltools.readme.io/docs/unified-conversion-api#target-conversion-formats\n",
      "Model is not in eval mode. Consider calling '.eval()' on your model prior to conversion\n",
      "Converting PyTorch Frontend ==> MIL Ops:  75%|███████▌  | 3/4 [00:00<00:00, 4166.53 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 38479.85 passes/s]\n",
      "Running MIL default pipeline:   0%|          | 0/69 [00:00<?, ? passes/s]/Users/surajmahapatra/Library/Python/3.9/lib/python/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:267: UserWarning: Output, '6', of the source model, has been renamed to 'var_6' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|██████████| 69/69 [00:00<00:00, 12016.57 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 32535.00 passes/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between PyTorch's grid sample before and after conversion: Note: PyTorch is fp32 and CoreML is fp16: 5.701563350157812e-05\n",
      "Difference between PyTorch's grid sample before and after conversion: Note: PyTorch is fp32 and CoreML is fp32: 5.701563350157812e-05\n",
      "Relative change in the difference: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import coremltools as ct\n",
    "\n",
    "# Pytorch Grid Model\n",
    "class PytorchGridSample(torch.nn.Module):\n",
    "    def forward(self, input, grid):\n",
    "        return torch.nn.functional.grid_sample(input, grid, align_corners=False)\n",
    "\n",
    "def convert_to_coreml(model, inputs, is_float16=True):\n",
    "    try:\n",
    "        traced_model = torch.jit.trace(model, example_inputs=inputs, strict=False)\n",
    "\n",
    "        # Precision\n",
    "        precision = ct.precision.FLOAT16 if is_float16 else ct.precision.FLOAT32\n",
    "        coreml_model = ct.converters.convert(\n",
    "            traced_model,\n",
    "            inputs=[ct.TensorType(shape=inputs[0].shape),\n",
    "                    ct.TensorType(shape=inputs[1].shape)],\n",
    "            compute_precision=precision\n",
    "        )\n",
    "\n",
    "        return coreml_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error during CoreML conversion: {e}\")\n",
    "        return None\n",
    "\n",
    "def compare_grid_samples_after_coreml_conversion(pt_model, inputs, is_float16):\n",
    "    try:\n",
    "        pt_out = pt_model(*inputs)\n",
    "        coreml_pt_model = convert_to_coreml(pt_model, inputs, is_float16)\n",
    "\n",
    "        input_names_coreml_pt = [i for i in coreml_pt_model.input_description]\n",
    "        input_data = {name: val.detach().numpy() for name, val in zip(input_names_coreml_pt, inputs)}\n",
    "\n",
    "        coreml_pt_out = torch.as_tensor(list(coreml_pt_model.predict(input_data).values())[0])\n",
    "\n",
    "        # Uncomment the line below to introduce an intentional issue in CoreML\n",
    "        # coreml_pt_out[0, 0, 0, 0] += 1.0\n",
    "\n",
    "        diff_pt_coreml = torch.norm(coreml_pt_out - pt_out)\n",
    "        return diff_pt_coreml\n",
    "    except Exception as e:\n",
    "        print(f\"Error during comparison: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load input tensors from .pt files\n",
    "        input_tensor = torch.load(\"feat_tensor.pt\").to(torch.float32)\n",
    "        grid = torch.load(\"grid_tensor.pt\").to(torch.float32)\n",
    "        inputs = [input_tensor, grid]\n",
    "\n",
    "        pt_model = PytorchGridSample()\n",
    "\n",
    "        diff_pt_coreml_fp16 = compare_grid_samples_after_coreml_conversion(pt_model, inputs, is_float16=True)\n",
    "        diff_pt_coreml_fp32 = compare_grid_samples_after_coreml_conversion(pt_model, inputs, is_float16=False)\n",
    "\n",
    "        if diff_pt_coreml_fp16 is not None and diff_pt_coreml_fp32 is not None:\n",
    "            print(f\"Difference between PyTorch's grid sample before and after conversion: Note: PyTorch is fp32 and CoreML is fp16: {diff_pt_coreml_fp16}\")\n",
    "            print(f\"Difference between PyTorch's grid sample before and after conversion: Note: PyTorch is fp32 and CoreML is fp32: {diff_pt_coreml_fp32}\")\n",
    "            print(f\"Relative change in the difference: {(diff_pt_coreml_fp16 - diff_pt_coreml_fp32) / diff_pt_coreml_fp32}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
